{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch01_04_DNN기초-이진분류모델.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiyeontae/SkillTreePython-DeepLearning/blob/main/01.%EB%94%A5%EB%9F%AC%EB%8B%9Dwith%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-basic/ch01_04_DNN%EA%B8%B0%EC%B4%88_%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch01.04 DNN기초 - 이진분류 모델\n",
        "\n",
        "\n",
        "---\n",
        "* 날짜:\n",
        "* 이름:\n",
        "\n",
        "## 학습내용\n",
        "    - 딥러닝을 이용한 이진분류 모델 구현\n",
        "    - 적절한 손실함수와 최적화 함수 정의\n",
        "    - 평가 및 예측\n",
        "\n",
        "## 학습자료\n",
        "\n",
        "* 모두의딥러닝 11장, 13장\n",
        "* 데이터\n",
        "  * `sornar.csv`\n",
        "  * `pima-indians-diabetes.csv`\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "seed=1\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "```\n",
        "\n",
        "```\n",
        "https://github.com/yebiny/SkillTreePython-DeepLearning.git\n",
        "```"
      ],
      "metadata": {
        "id": "sWs2kEC1_b-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "seed=1\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "3dvXKSSnDQ9V"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/yebiny/SkillTreePython-DeepLearning.git"
      ],
      "metadata": {
        "id": "VIgPnWNbUt_X",
        "outputId": "29322ff7-259f-4654-e27e-80c2ecc15d8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SkillTreePython-DeepLearning'...\n",
            "remote: Enumerating objects: 322, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 322 (delta 94), reused 88 (delta 64), pack-reused 178\u001b[K\n",
            "Receiving objects: 100% (322/322), 22.21 MiB | 19.70 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 소나 데이터 광물 예측\n",
        "---\n",
        "\n",
        "> 1988년 존스홉킨스 대학교의 세즈노프스키(Sejnowski) 교수는 광석과 일반 돌을 가져다 놓고 음파 탐지기를 쏜 후 그 결과를 데이터를 정리했습니다. 신경망이 광석과 돌을 얼마나 잘 구분하는지 알아보도록 합시다.\n",
        "\n",
        "```\n",
        "- 0~59 : 음파 탐지기를 이용해 얻은 값\n",
        "- 60: 광석 구분 {R, M}\n",
        "```\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0104-01.PNG?raw=true width=450>\n",
        "</p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KOmt3w8_rVe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 데이터 준비"
      ],
      "metadata": {
        "id": "TmgkVAdIfngb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **데이터 로드**\n",
        "* `sonar.csv`"
      ],
      "metadata": {
        "id": "cHXodXKif2BB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2sh64rMrANLD",
        "outputId": "2e1c03a1-3ded-486d-89f4-3ed899f67ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0       1       2       3       4       5       6       7       8   \\\n",
              "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
              "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
              "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
              "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
              "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
              "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
              "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
              "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
              "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
              "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
              "\n",
              "         9   ...      51      52      53      54      55      56      57  \\\n",
              "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
              "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
              "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
              "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
              "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
              "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
              "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
              "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
              "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
              "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
              "\n",
              "         58      59  60  \n",
              "0    0.0090  0.0032   R  \n",
              "1    0.0052  0.0044   R  \n",
              "2    0.0095  0.0078   R  \n",
              "3    0.0040  0.0117   R  \n",
              "4    0.0107  0.0094   R  \n",
              "..      ...     ...  ..  \n",
              "203  0.0193  0.0157   M  \n",
              "204  0.0062  0.0067   M  \n",
              "205  0.0077  0.0031   M  \n",
              "206  0.0036  0.0048   M  \n",
              "207  0.0061  0.0115   M  \n",
              "\n",
              "[208 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7af66180-1b92-4b1e-855f-56479b267388\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0346</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0177</td>\n",
              "      <td>0.0393</td>\n",
              "      <td>0.1630</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.2328</td>\n",
              "      <td>0.2684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0298</td>\n",
              "      <td>0.0564</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1018</td>\n",
              "      <td>0.1030</td>\n",
              "      <td>0.2154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.0437</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0351</td>\n",
              "      <td>0.1171</td>\n",
              "      <td>0.1257</td>\n",
              "      <td>0.1178</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.2529</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0353</td>\n",
              "      <td>0.0490</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.1354</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>0.1123</td>\n",
              "      <td>0.1945</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0126</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0272</td>\n",
              "      <td>0.0214</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.0655</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.1843</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0129</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7af66180-1b92-4b1e-855f-56479b267388')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7af66180-1b92-4b1e-855f-56479b267388 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7af66180-1b92-4b1e-855f-56479b267388');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "path = '/content/SkillTreePython-DeepLearning/dataset/sonar.csv'\n",
        "dataset = pd.read_csv(path, header =None)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **데이터 전처리**"
      ],
      "metadata": {
        "id": "0NL7LyHXrhoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder #머신러닝 라이브러리\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def path2dataset_sonar(path):\n",
        "\n",
        "  # 불러오기\n",
        "  dataset =  pd.read_csv(path,  # 엑셀이나 csv 등 정현 데이터를 불러오기\n",
        "                       header=None, # 첫번째 샘플이 헤더로 읽히지 않도록 설정\n",
        "                       \n",
        "                       ) \n",
        "  #print(dataset.shape)  #데이터형식 : 판다스의 데이터프레임\n",
        "\n",
        "  dataset = dataset.values # 데이터 형식 : 넘파이 배열로 변환\n",
        "  # x-y 분할 -> 넘파이 배열을 슬라이싱하는 기법\n",
        "  x = dataset[:, 0:-1] # ( : 모든행, 첫번째부터 마지막 전까지의 열)\n",
        "  y = dataset[:, -1] # ( : 모든행, 마지막열)\n",
        "  #print(x.shape, y.shape)\n",
        "\n",
        "\n",
        "# 정규화(속셩별로 데이터의 스케일을 조정)- x데이터만 해준다\n",
        "  scaler = StandardScaler()\n",
        "  x = scaler.fit_transform(x)\n",
        "  #print(dataset.shape, dataset.dtype) # 데이터형식 : 넘파이 배열\n",
        "\n",
        "# 라벨링 y {R. M}  ->{0,1}\n",
        "  labeling = LabelEncoder()\n",
        "  y = labeling.fit_transform(y)\n",
        "  print(labeling.classes_)\n",
        " \n",
        "  # train-test 분할\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =  0.3)\n",
        "  \n",
        "  return x_train, x_test, y_train, y_test\n",
        "\n",
        "path = '/content/SkillTreePython-DeepLearning/dataset/sonar.csv'\n",
        "x_train, x_test, y_train, y_test = path2dataset_sonar(path)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "print(f'첫번째 샘플 x: {x_train[0]}')\n",
        "print(f'첫번째 샘플 y: {y_train[0]}')"
      ],
      "metadata": {
        "id": "CoWLi5NgraBV",
        "outputId": "62ee2295-8560-43a1-d5d3-322bfe724ce7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['M' 'R']\n",
            "(145, 60) (63, 60) (145,) (63,)\n",
            "첫번째 샘플 x: [-1.20615835 -0.60328999 -0.38951266 -0.74095829 -0.42769865 -0.38787239\n",
            " -0.34469365 -1.44088297 -0.5182194  -0.45236879 -0.18289791  0.05209041\n",
            " -0.26955286 -0.99445209 -1.51758067 -0.79015248 -0.18051523  0.04707449\n",
            "  0.1437185   0.24026107  0.5168784   0.78907491  0.85716302  0.70153924\n",
            "  0.89825313  1.24498292  1.2153686   1.14478085  0.97060315  0.20330806\n",
            " -1.34007377 -0.67947475 -0.2559012   0.42467788  1.51534195  2.09215621\n",
            "  1.90399769  1.32279875  0.63194033 -0.0606331  -0.12801415 -0.32196152\n",
            "  0.4872258   1.16736727  0.67014029  0.46378392 -0.43291895 -0.89171619\n",
            " -0.64205439 -0.60328372 -0.96570457 -0.27262999 -0.45562647 -0.28021418\n",
            " -0.80479837 -0.92998098 -1.12970836 -1.07665762 -0.76888703 -0.3600787 ]\n",
            "첫번째 샘플 y: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 예측값 분포 확인"
      ],
      "metadata": {
        "id": "J49Ys-SNBKyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=dataset[60])"
      ],
      "metadata": {
        "id": "3vlsRwuoBMcY",
        "outputId": "8d5987a7-1edc-49c7-d92c-f0c127294b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f10acbfefd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 모델\n",
        "\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0104-02.PNG?raw=true width=500>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "DHshtWB9r0be"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **모델 생성**"
      ],
      "metadata": {
        "id": "J94jFpWyr2k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers, utils\n",
        "\n",
        "#60-> 30->1\n",
        "def bulid_models():\n",
        "  x = layers.Input(shape=(60))\n",
        "  y = layers.Dense(30, activation= 'relu')(x)\n",
        "  y = layers.Dense(1, activation = 'sigmoid')(y)   #회귀 문제 경우, 마지막 레이어의 activation을 사용하지 않는다.\n",
        "  model = models.Model(x,y)\n",
        "\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "5BZG1z90rsGc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **모델 시각화**\n",
        "\n",
        "* `model.summary()`\n",
        "* `utils.plot_model()`"
      ],
      "metadata": {
        "id": "1yqXLbEyx5QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model =bulid_models()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "dKCT38Fsr6dF",
        "outputId": "9a600d17-b6c6-4eaf-aca5-45e5fdd22d0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 60)]              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 30)                1830      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,861\n",
            "Trainable params: 1,861\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 학습"
      ],
      "metadata": {
        "id": "gLuvsUFmwzPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **모델 컴파일**\n",
        "\n",
        "```\n",
        "model.compile(loss, optimizer, metrics) \n",
        "```\n",
        "* `loss` : 이진분류에서는 binary_crosentropy\n",
        "* `optimizer` : 'adam' (문제와 관련 없다\n",
        "* `metrics`: \n",
        "  * 추가적인 옵션\n",
        "  * 딥러닝 알고리즘에 필수 요소는 아니다.\n",
        "  * 사용자 편의 (정확도)"
      ],
      "metadata": {
        "id": "fwQboNHp3EHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy' , \n",
        "              optimizer = 'adam', \n",
        "              metrics=['accuracy']) "
      ],
      "metadata": {
        "id": "SASPIskxgfRY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **학습**\n",
        "\n",
        "```\n",
        "model.fit(x_train, y_train, epochs, batch_size)\n",
        "```\n",
        "* `x_train` : 넘파이 혹은 텐서 형식의 인풋 데이터\n",
        "* `y_train` : 넘파이 혹은 텐서 형식의 아웃풋 데이터\n",
        "* `epochs` : 학습 횟수\n",
        "* `batch_size` : 배치 사이즈 (업데이트 한번에 사용될 샘플 개수)"
      ],
      "metadata": {
        "id": "JukUpWB4gfRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=100, batch_size=10)"
      ],
      "metadata": {
        "id": "9bgbpUhogfRY",
        "outputId": "b51597cf-39c6-408d-a099-011902a24f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 1ms/step - loss: 0.6797 - accuracy: 0.5655\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.7103\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7931\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8345\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8621\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.8897\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8966\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9310\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2589 - accuracy: 0.9310\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.9379\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9448\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9586\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9655\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9862\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9862\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9862\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9931\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9931\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9931\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9931\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9931\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9931\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f10a388e7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 검증 및 예측\n"
      ],
      "metadata": {
        "id": "DyFOnqyNw5_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **검증**\n",
        "\n",
        "```\n",
        "model.evaluate(x_test, y_test)\n",
        "```\n",
        "* `x_test` : 넘파이 혹은 텐서 형식의 인풋 테스트 데이터\n",
        "* `y_test` : 넘파이 혹은 텐서 형식의 아웃풋 테스트 데이터"
      ],
      "metadata": {
        "id": "qlalKZ-a04c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "uHGyMlf60zng",
        "outputId": "c795ae42-40c2-4fd0-8800-3e5010938fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.8413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6330443024635315, 0.841269850730896]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **예측**\n",
        "\n",
        "```\n",
        "model.predict(x_test)\n",
        "```\n",
        "* `x_test` : 넘파이 혹은 텐서 형식의 인풋 테스트 데이터\n",
        "* `y_test` : 넘파이 혹은 텐서 형식의 아웃풋 테스트 데이터"
      ],
      "metadata": {
        "id": "BITPUIOj07Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred = y_pred.flatten()\n",
        "y_pred = np.round(y_pred) #반올림\n",
        "for i in range(10):\n",
        "  print('y true:', y_test[i], 'y_pred', y_pred[i])\n",
        " \n"
      ],
      "metadata": {
        "id": "KfDHL4PRv8YD",
        "outputId": "dcd56551-5fc3-497e-ce23-237ac8a40ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y true: 0 y_pred 0.0\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 1 y_pred 0.0\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 1 y_pred 0.0\n",
            "y true: 1 y_pred 0.0\n",
            "y true: 1 y_pred 0.0\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 0 y_pred 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 예측 시각화"
      ],
      "metadata": {
        "id": "gThN4RCR0_HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "#혼돈행렬\n",
        "cm= confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "ConfusionMatrixDisplay(cm).plot(cmap='BuGn')\n"
      ],
      "metadata": {
        "id": "TG533VyLwDaK",
        "outputId": "a2a05ddf-5ce8-4e4b-f6fb-5ba91b130ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[32  2]\n",
            " [ 8 21]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f10a401b750>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 과제\n",
        "---"
      ],
      "metadata": {
        "id": "ZFrRTgcyipYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 과제1. 이진분류 문제 정리\n",
        "\n",
        "* 예측값의 범위 : 0또는1\n",
        "* 예측값의 shape : (샘플수 ,1)\n",
        "* 아웃풋 레이어의 노드 개수 : 1\n",
        "* 아웃풋 레이어의 activation :  sigmoid\n",
        "* 손실함수 (loss) : binary_crossentropy\n",
        "* 평가함수 (metrics) : accuracy"
      ],
      "metadata": {
        "id": "xjnJSLgXK_Pp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 과제2. 한 셀에 코드 정리하기\n",
        "\n",
        "* 추가 연습\n",
        "  * 모델의 깊이(depth)를 늘려가며 학습해 보세요.\n",
        "  * 모델의 너비(width)를 늘려가며 학습해 보세요."
      ],
      "metadata": {
        "id": "ZvFAB78P1B_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 로드\n",
        "path = '/content/SkillTreePython-DeepLearning/dataset/sonar.csv'\n",
        "dataset = pd.read_csv(path, header =None)\n",
        "\n",
        "#데이터 전처리\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder #머신러닝 라이브러리\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def path2dataset_sonar(path):\n",
        "\n",
        "  # 불러오기\n",
        "  dataset =  pd.read_csv(path,  # 엑셀이나 csv 등 정현 데이터를 불러오기\n",
        "                       header=None, # 첫번째 샘플이 헤더로 읽히지 않도록 설정\n",
        "                       \n",
        "                       ) \n",
        "  #print(dataset.shape)  #데이터형식 : 판다스의 데이터프레임\n",
        "\n",
        "  dataset = dataset.values # 데이터 형식 : 넘파이 배열로 변환\n",
        "  # x-y 분할 -> 넘파이 배열을 슬라이싱하는 기법\n",
        "  x = dataset[:, 0:-1] # ( : 모든행, 첫번째부터 마지막 전까지의 열)\n",
        "  y = dataset[:, -1] # ( : 모든행, 마지막열)\n",
        "  #print(x.shape, y.shape)\n",
        "\n",
        "\n",
        "# 정규화(속셩별로 데이터의 스케일을 조정)- x데이터만 해준다\n",
        "  scaler = StandardScaler()\n",
        "  x = scaler.fit_transform(x)\n",
        "  #print(dataset.shape, dataset.dtype) # 데이터형식 : 넘파이 배열\n",
        "\n",
        "# 라벨링 y {R. M}  ->{0,1}\n",
        "  labeling = LabelEncoder()\n",
        "  y = labeling.fit_transform(y)\n",
        "  print(labeling.classes_)\n",
        " \n",
        "  # train-test 분할\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =  0.3)\n",
        "  \n",
        "  return x_train, x_test, y_train, y_test\n",
        "\n",
        "#60-> 30->1\n",
        "def bulid_models():\n",
        "  x = layers.Input(shape=(60))\n",
        "  y = layers.Dense(20, activation= 'relu')(x)\n",
        "  y = layers.Dense(30, activation= 'relu')(x)\n",
        "  y = layers.Dense(1, activation = 'sigmoid')(y)   #회귀 문제 경우, 마지막 레이어의 activation을 사용하지 않는다.\n",
        "  model = models.Model(x,y)\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "path = '/content/SkillTreePython-DeepLearning/dataset/sonar.csv'\n",
        "x_train, x_test, y_train, y_test = path2dataset_sonar(path)\n",
        "\n",
        "\n",
        "\n",
        "#모델 생성\n",
        "from tensorflow.keras import models, layers, utils\n",
        "\n",
        "\n",
        "\n",
        "#모델 시각화\n",
        "model =bulid_models()\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(loss = 'binary_crossentropy' , \n",
        "              optimizer = 'adam', \n",
        "              metrics=['accuracy']) \n",
        "\n",
        "\n",
        "#모델 학습\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=10)\n",
        "\n",
        "#모델 예측\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = y_pred.flatten()\n",
        "y_pred = np.round(y_pred) #반올림\n",
        "for i in range(10):\n",
        "  print('y true:', y_test[i], 'y_pred', y_pred[i])\n",
        " \n"
      ],
      "metadata": {
        "id": "v5WYSd9a1Cz4",
        "outputId": "0c8647c3-ea17-4d64-a906-9d993f196c76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['M' 'R']\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 60)]              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 30)                1830      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,861\n",
            "Trainable params: 1,861\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6207\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.6759\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7241\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7862\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8207\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8483\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8759\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.9241\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.9310\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.9310\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.9379\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.9517\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9517\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9586\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9655\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9517\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.9793\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9793\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9862\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.9862\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9862\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9862\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9862\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9862\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9862\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9931\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9931\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.9931\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9931\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0150 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 0 y_pred 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 과제 3. 피마 인디언 당뇨병 예측\n",
        "\n",
        "\n",
        "* `pima-indians-diabetes.csv`\n",
        "```\n",
        "df = pd.read_csv(data_path,\n",
        "                names = [\"pregnant\", \"plasma\", \"pressure\", \"thickness\", \"insulin\", \"BMI\", \"pedigree\", \"age\", \"class\"])\n",
        "```"
      ],
      "metadata": {
        "id": "2K0mAdPzjOAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 로드\n",
        "path = '/content/SkillTreePython-DeepLearning/dataset/pima-indians-diabetes.csv'\n",
        "dataset = pd.read_csv(path, header =None)\n",
        "dataset\n",
        "\n",
        "#데이터 전처리\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder #머신러닝 라이브러리\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def path2dataset_sonar(path):\n",
        "\n",
        "  # 불러오기\n",
        "  dataset =  pd.read_csv(path,  # 엑셀이나 csv 등 정현 데이터를 불러오기\n",
        "                       header=None, # 첫번째 샘플이 헤더로 읽히지 않도록 설정\n",
        "                       \n",
        "                       ) \n",
        "  #print(dataset.shape)  #데이터형식 : 판다스의 데이터프레임\n",
        "\n",
        "  dataset = dataset.values # 데이터 형식 : 넘파이 배열로 변환\n",
        "  # x-y 분할 -> 넘파이 배열을 슬라이싱하는 기법\n",
        "  x = dataset[:, 0:-1] # ( : 모든행, 첫번째부터 마지막 전까지의 열)\n",
        "  y = dataset[:, -1] # ( : 모든행, 마지막열)\n",
        "  #print(x.shape, y.shape)\n",
        "\n",
        "\n",
        "# 정규화(속셩별로 데이터의 스케일을 조정)- x데이터만 해준다\n",
        "  scaler = StandardScaler()\n",
        "  x = scaler.fit_transform(x)\n",
        "  #print(dataset.shape, dataset.dtype) # 데이터형식 : 넘파이 배열\n",
        "\n",
        "# 라벨링 y {R. M}  ->{0,1}\n",
        "  labeling = LabelEncoder()\n",
        "  y = labeling.fit_transform(y)\n",
        "  print(labeling.classes_)\n",
        " \n",
        "  # train-test 분할\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =  0.3)\n",
        "  \n",
        "  return x_train, x_test, y_train, y_test\n",
        "\n",
        "#60-> 30->1\n",
        "def bulid_models():\n",
        "  x = layers.Input(shape=(8))\n",
        "  y = layers.Dense(30, activation= 'relu')(x)\n",
        "  y = layers.Dense(1, activation = 'sigmoid')(y)   #회귀 문제 경우, 마지막 레이어의 activation을 사용하지 않는다.\n",
        "  model = models.Model(x,y)\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "path = '/content/SkillTreePython-DeepLearning/dataset/pima-indians-diabetes.csv'\n",
        "x_train, x_test, y_train, y_test = path2dataset_sonar(path)\n",
        "\n",
        "\n",
        "\n",
        "#모델 생성\n",
        "from tensorflow.keras import models, layers, utils\n",
        "\n",
        "\n",
        "\n",
        "#모델 시각화\n",
        "model = bulid_models()\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(loss = 'binary_crossentropy' , \n",
        "              optimizer = 'adam', \n",
        "              metrics=['accuracy']) \n",
        "\n",
        "\n",
        "#모델 학습\n",
        "model.fit(x_train, y_train, epochs=50, batch_size=10)\n",
        "\n",
        " #모델 예측\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = y_pred.flatten()\n",
        "y_pred = np.round(y_pred) #반올림\n",
        "for i in range(10):\n",
        "  print('y true:', y_test[i], 'y_pred', y_pred[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "Ppi8p2S_HsVb",
        "outputId": "904c159a-5271-4f4d-de3e-71df54a59def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1.]\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 8)]               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 30)                270       \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 301\n",
            "Trainable params: 301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "54/54 [==============================] - 1s 3ms/step - loss: 0.7186 - accuracy: 0.5326\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.7114\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7505\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 0s 982us/step - loss: 0.5138 - accuracy: 0.7598\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7691\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 0s 995us/step - loss: 0.4857 - accuracy: 0.7709\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7728\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7765\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7784\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7840\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7840\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 0s 932us/step - loss: 0.4592 - accuracy: 0.7896\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7914\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7933\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7896\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7933\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7914\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7858\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7896\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7896\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7896\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7952\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7933\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 0s 944us/step - loss: 0.4428 - accuracy: 0.7970\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7896\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7877\n",
            "Epoch 27/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7970\n",
            "Epoch 28/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7914\n",
            "Epoch 29/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7933\n",
            "Epoch 30/50\n",
            "54/54 [==============================] - 0s 934us/step - loss: 0.4353 - accuracy: 0.7970\n",
            "Epoch 31/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.7952\n",
            "Epoch 32/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7970\n",
            "Epoch 33/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.7896\n",
            "Epoch 34/50\n",
            "54/54 [==============================] - 0s 931us/step - loss: 0.4307 - accuracy: 0.7989\n",
            "Epoch 35/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.8007\n",
            "Epoch 36/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8007\n",
            "Epoch 37/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.8026\n",
            "Epoch 38/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8082\n",
            "Epoch 39/50\n",
            "54/54 [==============================] - 0s 921us/step - loss: 0.4270 - accuracy: 0.8007\n",
            "Epoch 40/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.8045\n",
            "Epoch 41/50\n",
            "54/54 [==============================] - 0s 987us/step - loss: 0.4258 - accuracy: 0.8063\n",
            "Epoch 42/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8082\n",
            "Epoch 43/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.8119\n",
            "Epoch 44/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8101\n",
            "Epoch 45/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8082\n",
            "Epoch 46/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8119\n",
            "Epoch 47/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.8138\n",
            "Epoch 48/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.8138\n",
            "Epoch 49/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8119\n",
            "Epoch 50/50\n",
            "54/54 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8138\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 1 y_pred 0.0\n",
            "y true: 1 y_pred 0.0\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 1 y_pred 1.0\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 0 y_pred 0.0\n",
            "y true: 1 y_pred 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "#혼돈행렬\n",
        "cm= confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "ConfusionMatrixDisplay(cm).plot(cmap='BuGn')\n"
      ],
      "metadata": {
        "id": "LT3uCj0DTnvX",
        "outputId": "2ab6281b-a447-400d-de54-fa3d1bf91e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[127  14]\n",
            " [ 36  54]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f109e1967d0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 과제 4. 생각해보기\n",
        "\n",
        "데이터가 불균형 할 때 딥러닝에서는 어떠한 방법을 써서 이를 해결 하나요? \n"
      ],
      "metadata": {
        "id": "s4VjzrycjTUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tcMHkA5BjSho"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Vkk5_JZDROhE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}